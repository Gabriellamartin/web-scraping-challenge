{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/gabriellamartin/.wdm/drivers/chromedriver/mac64/88.0.4324.96/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "#instal chrome drive manager\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page I want to read and scrape with pandas and beautifil soup\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n",
      "Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all pages\n",
    "#  Stu_Splinter.ipynb code to scrape url = 'https://mars.nasa.gov/'\n",
    "for x in range(50):\n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Retrieve all elements that contain book information\n",
    "    articles = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    # Iterate through each book\n",
    "    for article in articles:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        h3 = article.find('h3')\n",
    "        link = h3.find('a')\n",
    "        href = link['href']\n",
    "        title = link['title']\n",
    "        print('-----------')\n",
    "        print(title)\n",
    "        print('https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest' + href)\n",
    "\n",
    "    # Click the 'Next' button on each page\n",
    "    try:\n",
    "        browser.links.find_by_partial_text('next').click()\n",
    "          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page I want to read and scrape with pandas and beautifil soup\n",
    "url = 'https://www.jpl.nasa.gov/images?search=&category=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages\n",
    "#  Stu_Splinter.ipynb code to scrape url = 'https://mars.nasa.gov/'\n",
    "for x in range(50):\n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Retrieve all elements that contain book information\n",
    "    articles = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    # Iterate through each book\n",
    "    for article in articles:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        h3 = article.find('h3')\n",
    "        link = h3.find('a')\n",
    "        href = link['href']\n",
    "        title = link['title']\n",
    "        print('-----------')\n",
    "        print(title)\n",
    "        print('https://www.jpl.nasa.gov/images?search=&category=Mars' + href)\n",
    "\n",
    "    # Click the 'Next' button on each page\n",
    "    try:\n",
    "        browser.links.find_by_partial_text('next').click()\n",
    "          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
